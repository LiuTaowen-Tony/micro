{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tl2020/micro/.venv/lib64/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from functools import partial\n",
    "from torch import nn\n",
    "import dataclasses\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import token_data\n",
    "import micro_model\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class TesterConfig:\n",
    "    batch_size: int = 10\n",
    "    max_seq_len: int = 1024\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class Tester:\n",
    "    def __init__(self, model, dataset, tokenizer, loss, config: TesterConfig = None):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.model = model\n",
    "        self.dataset = dataset\n",
    "        self.config = config if config is not None else TesterConfig()\n",
    "        self.dataloader = DataLoader(self.dataset, batch_size=self.config.batch_size, num_workers=1, collate_fn=partial(\n",
    "            token_data.data_collator, self.tokenizer, self.config.max_seq_len))\n",
    "        self.model = self.model.to(self.config.device)\n",
    "        self.model.eval()\n",
    "        self.model.to(torch.bfloat16)\n",
    "        self.loss = loss\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def test(self):\n",
    "        i = 0\n",
    "        for batch in self.dataloader:\n",
    "            batch[\"input_ids\"] = batch[\"input_ids\"].to(self.config.device)\n",
    "            batch[\"labels\"] = batch[\"labels\"].to(self.config.device)\n",
    "            i += 1\n",
    "            logits = self.model.forward(batch[\"input_ids\"])\n",
    "            if not isinstance(logits, torch.Tensor):\n",
    "                logits = logits.logits\n",
    "            loss = self.loss(logits.view(-1, logits.size(-1)), batch[\"labels\"].view(-1))\n",
    "            print(f\"Loss: {loss}\")\n",
    "            if i == 10:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_dataset(path=\"cerebras/SlimPajama-627B\", split='test', trust_remote_code=True, streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v0.1\")\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3.0625\n",
      "Loss: 2.484375\n",
      "Loss: 3.453125\n",
      "Loss: 3.328125\n",
      "Loss: 2.84375\n",
      "Loss: 2.953125\n",
      "Loss: 3.515625\n",
      "Loss: 2.65625\n",
      "Loss: 3.28125\n",
      "Loss: 3.03125\n"
     ]
    }
   ],
   "source": [
    "tester1 = Tester(model, dataset, tokenizer, loss)\n",
    "tester1.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3571887/4136072741.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(\"/home/tl2020/micro/micro_model_sft.pth\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = token_data.load_tokenizer()\n",
    "\n",
    "model = micro_model.get_model().to('cpu').to(torch.bfloat16)\n",
    "# ckpt = torch.load('/home/tl2020/micro/micro_model.pth')\n",
    "# ckpt = torch.load(\"/home/tl2020/micro/micro_lm_sft/8bh1d845/checkpoints/epoch=2-step=1417.ckpt\")\n",
    "ckpt = torch.load(\"/home/tl2020/micro/micro_model_sft.pth\")\n",
    "model.load_state_dict(ckpt)\n",
    "# print(ckpt[\"state_dict\"].keys())\n",
    "# print({ k[6:]: v for k, v in ckpt[\"state_dict\"].items() })\n",
    "# model.load_state_dict({ k[6:]: v for k, v in ckpt[\"state_dict\"].items() })\n",
    "# model.load_state_dict(ckpt)\n",
    "# tester2 = Tester(model, dataset, tokenizer, loss)\n",
    "# tester2.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chat_wrapper import ChatWrapper, GenerationConfig\n",
    "chat = ChatWrapper(model, tokenizer, torch.bfloat16, \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract:\n",
      "Quentin's next paper, titled \"Creating a Diverse Perspective in Environmental Issues: An Interdisciplinary Approach,\" examines the effects of climate change on different ecosystems, including forests, rivers, and the seas. The paper explores how environmental change is influenced by environmental factors such as temperature, precipitation, and moisture, and how these factors affect human health, ecosystem balance, and ecological stability.\n",
      "\n",
      "The paper explores how climate change can affect ecosystem health, such as altering weather patterns, changing nutrient availability, and reducing heat loss, among other factors. The paper explores how different species have evolved to adapt to these changes, and how environmental factors can impact species' survival. The paper also examines the relationship between climate change and environmental change, which affects the natural resources and ecosystems that depend on it.\n",
      "\n",
      "The paper concludes with a discussion of the implications of climate change on human health, ecosystem stability, and environmental resilience. The abstract provides a concrete example of how environmental change can have a significant impact on ecosystems, and how climate change can be influenced by various factors, including climate change. It highlights the importance of research and collaboration between academic institutions and environmental research to support research that can benefit society and the planet. Finally, the paper concludes with a call for further research and collaboration\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "<|user|>\n",
    "What is the abstract of Quentin's next paper?\n",
    "</s>\n",
    "<|assistant|>\n",
    "\"\"\"\n",
    "print(chat.generate(text, GenerationConfig(256))[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " World Heritage Site. From this great historical relic you will find some of the best museums in Spain, including the Sainte Tinta Museum, which houses one of the most important and famous religious collections in Spain and several more at the same time.\n",
      "The Mezquita is considered to be one of the most important monuments of Spanish Culture and is only 1.2 km from Cordoba and has 10 museums with collections from the Middle Ages. It is among the best preserved monuments in Spain with over 100 of them surviving in the years 1845-1895.\n",
      "Alberta's three major monuments - the House of Mosques, the Cathedral of El Arbol and the Main Mosque are covered with a magnificent collection of wood, polychrome and pendent. Alberta's museums include the National Library and the Bloc de Santillana in the city, which is an extraordinary collection of sculptures, drawings and many more.\n",
      "Visit Almota's famous Archaeological Museum to see two of the oldest tombs in Almer√≠a. The museum houses more than 100 collections and was built in 1863 and has more than 2500 artefacts. The Museum has over 200,000 items of human origin and is constantly updated to ensure the best protection. The Museum is open daily from 8.00 am to 1.00 pm and from 10.00 am to 3.00 pm.\n",
      "Spain's main prefecture is Bialystok and the administrative centre of the city is the modern Alcatraz. It has a large museum of antiquities and the area around Alcatraz has many original period buildings and is a natural draw for people who are interested in discovering the hidden treasures in the city.\n",
      "Enjoy some of the best hiking and biking around the province of Bialystok in the province of Lourdes. The national park has many hiking trails that allow you to explore the nature reserves of Lourdes in the presence of nature. This is one of the best places to relax, and you can also visit the tourist sights, especially the Plaza de la Torre, where you will find different tombs.\n",
      "The mountains of the B√°lint and its mountains are characterized by many interesting features. On the coast, a small castle, and the cathedral of Saint Augustine, are the main\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(chat.generate(\"Some of the most glorious historical attractions in Spain date from the period of Muslim rule, including The\"\n",
    "\"Mezquita, built as the Great Mosque of Cordoba and the Medina Azahara, also in C ¬¥ ordoba and now in ruins but ¬¥\"\n",
    "\"still visitable as such and built as the Madinat al-Zahra, the Palace of al-Andalus; and the Alhambra in Granada, a\" , \n",
    "GenerationConfig(512))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: China began the race with the founding of the Beijing Olympics in 1909, 2000 and 2002,\n",
      "for the record. The event, known as the \"Little Miss America\" (aka ‚Äã\"Golden Time\"), was conceived to create the first-ever Olympic torch relay, taking place in Beijing from February 23 to March 13, 2008, when the\n",
      "golden hour was measured.\n",
      "Q: What were the route goals?\n",
      "A: The city of Beijing\n",
      "Q: What was the exact day when the torch relay was launched?\n",
      "A: It was on March 24, 2007.\n",
      "Q: Did you take the same roads, climbs, climbs, etc. in Beijing?\n",
      "A: The only problems I had with the trip were the weather and the lack of fuel. So I had to drive on one of these, and they were almost a mile from my house.\n",
      "Q: How did you plan this?\n",
      "A: The track itself is no more than a single parkway, but the lane you take, it was supposed to be the single most important place for the events of the Olympics. So this meant that the riders (on the road) couldn't get up and down, and then the trucks could come and go. So I had to build my first six-metre circuit.\n",
      "Q: What were the roads' limits?\n",
      "A: The paved streets were as long as the path leading to the Olympic grounds.\n",
      "Q: What was the longest road?\n",
      "A: It was narrow, but it was a very good access road. It used to go straight downhill, which you had to climb out on, and then downhill.\n",
      "Q: How did the track become a home for the Olympic torch relay?\n",
      "A: The first track was made up of over 60,000 sqm (50,000 sqm) in 1908. The roads were re-arranged, and used by the military to support the 1914 Olympic Games. The tracks were then built on the pavement. In 1932, the first link road was made, in 1936 the road was extended, but the original 10,000sqm (1,000,000sqm) was used to support\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "The 2008 Summer Olympics torch relay was run from March 24 until August 8, 2008, prior to the 2008 Summer\n",
    "Olympics, with the theme of ‚Äúone world, one dream‚Äù. Plans for the relay were announced on April 26, 2007, in\n",
    "Beijing, China. The relay, also called by the organizers as the ‚ÄúJourney of Harmony‚Äù, lasted 129 days and carried\n",
    "the torch 137,000 km (85,000 mi) ‚Äì the longest distance of any Olympic torch relay since the tradition was started\n",
    "ahead of the 1936 Summer Olympics.\n",
    "After being lit at the birthplace of the Olympic Games in Olympia, Greece on March 24, the torch traveled to the Panathinaiko Stadium in Athens, and then to Beijing, arriving on March 31. From Beijing, the torch was\n",
    "following a route passing through six continents. The torch has visited cities along the Silk Road, symbolizing\n",
    "ancient links between China and the rest of the world. The relay also included an ascent with the flame to the top of\n",
    "Mount Everest on the border of Nepal and Tibet, China from the Chinese side, which was closed specially for the\n",
    "event.\n",
    "Q: What was the theme\n",
    "A: ‚Äúone world, one dream‚Äù.\n",
    "Q: What was the length of the race?\n",
    "A: 137,000 km\n",
    "Q: Was it larger than previous ones?\n",
    "A: No.\n",
    "Q: Where did the race begin?\n",
    "\"\"\"\n",
    "\n",
    "print(chat.generate(text, GenerationConfig(512))[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
